# -*- coding: utf-8 -*-
"""A2_MT20104_MT20133_Phd19006.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d3cyYsG8A-O97yb2FSzko9Tm9AxtvO7H

Dataset Link: https://www.kaggle.com/t/eef896d3115a4e2281f85ab9bdc9ad97
"""

import os
# os.environ['KAGGLE_USERNAME'] = "richadwivedi"
# os.environ['KAGGLE_KEY'] = "1462d815580695348ef4bf8d3edfbfbe"

# !kaggle competitions download -c bdmh2021-a2

"""IMPORT STATEMENTS

"""

import numpy as np
import pandas as pd
import seaborn as sns
import sys
import matplotlib as map
import matplotlib.pyplot as plt
from sklearn.metrics import matthews_corrcoef
# from imblearn.under_sampling import RandomUnderSampler
from sklearn.ensemble import RandomForestClassifier
from sklearn.utils import resample

from collections import Counter

# from sklearn.preprocessing import LabelEncoder
# from zipfile import ZipFile


#To ignore warnings.
# import warnings
# warnings.filterwarnings('ignore')

#saving model
# from sklearn.externals import joblib



inFile1=""
inFile2=""
outFile=""


#input separator -i
input_sep1=sys.argv[1]
inFile1 = sys.argv[2]
input_sep2=sys.argv[3]
inFile2 = sys.argv[4]
output_sep=sys.argv[5]
outFile = sys.argv[6]

"""LOADING DATASET"""

def loading_dataset():
    #loading train and test data
    # with ZipFile('RNA_Train.csv.zip', 'r') as zipObj:
    #     zipObj.extractall()
    #Reading CSV Files
    #train= pd.read_csv('RNA_Train.csv')
    #test= pd.read_csv('test.csv')
    train = pd.read_csv(inFile1)
    test = pd.read_csv(inFile2)

    return train,test

train,test=loading_dataset()

print("Training Data")
print(train.head())

print("Test Data")
print(test.head())

"""DATA OVERVIEW"""

print("Shape of the Data ", train.shape)

#Number of Rows in the dataset
print("Number of Rows are:",train.shape[0])

#Number of Columns/features in dataset
print("Number of Columns are:",train.shape[1])

#List of Available features in dataset
print("Available Features are:",train.columns.tolist())

# Checking type of Value are Available in Features.
print(train.info())

#Checking is data contains any null/nan values
print(train.isnull().sum())

#Let's check our target class "label" is balanced or not
print(train["label"].value_counts())
# since their are 291963 values of class 0 and 38899 values of class 1.
#so the class is highly unbalanced

#Visualization of unbalanced class
sns.countplot(train["label"],palette="flare")
plt.show()

"""ENCODING SEQUENCE FEATURE"""

#As sequence feature is categorical so we need to convert it into numerical vale to use these for training in machine learning models

#Finding unique list and total number of unique alphabets 

list_single_pattern=[]
for seq in train['Sequence']:
  list_single_pattern.append(list(set(seq)))

flat_list = [item for sublist in list_single_pattern for item in sublist]
newlist=list(set(flat_list))

print("Number of Unique alphabets: ",len(newlist))
print("\nlist of unique alphabets:")
print(newlist)

#Converting the list of alphabets in dictionary an alloting unique number as label to each alphabet

unique_dict = {}
for index, val in enumerate(newlist):
    unique_dict[val] = index+1
print("Encoded alphabets of RNA Sequence:")
print(unique_dict)

#Encoding sequences in a train and test data into numerical values

def encode_data(df):

  encoded_list = []
  for i in df['Sequence'].values:
    encode_val = []
    for value in i:
      encode_val.append(unique_dict.get(value, 0))
    encoded_list.append(np.array(encode_val))
  
  return encoded_list

train_encoded = encode_data(train) 
test_encoded = encode_data(test)

#data after encoding
#print("encoded training data:")
#print(train_encoded)

#Converting obtained data into dataframe

#Converting train data
train_df=pd.DataFrame(train_encoded)
train_df["label"]=train["label"]

#Converting test data
test_df=pd.DataFrame(test_encoded)

#Dataframe obtained after encoding
print("encoded training dataframe:")
print(train_df)

# plt.subplots(figsize=(13,10))

#Visulazing the correlation between all the features
#sns.heatmap(df.corr(method='pearson'), annot = True)
# sns.heatmap(train_df.corr(), annot = True)

"""DATA BALANCING"""

def data_balancing(df):
    #Function for handling class imbalance.
    
    df_majority = df[df.label==0]
    df_minority = df[df.label==1]

    #Resampling data.
    traindf = resample(df_minority, replace=True,  n_samples=df_majority.shape[0], random_state=42) 

    # concatenating resampled class with orginal training data.
    train1 = pd.concat([df_majority, traindf])

    return train1

train1=data_balancing(train_df)

# Display new class counts
print("display new class counts:")
print(train1.label.value_counts())

#Visualization after balancing 
sns.countplot(train1["label"],palette="flare")
plt.show()

#Spliing into x_train and y_train for testing purpose.

def split(df):
    y_train=df["label"]
    x_train=df.drop("label",axis=1)

    return x_train,y_train

x_train,y_train=split(train1)

# print(x_train)
# print(y_train)

"""TRAINING DATA"""

def train_data(x_train,y_train):

    #https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html

    #Applying random forest classifier.
    clf = RandomForestClassifier(n_estimators=100)
    #Training model.
    clf.fit(x_train,y_train)
    #Saving model in pickel file.
    #joblib.dump(clf, '/content/drive/MyDrive/bdmh_assignment2/random_forest.pkl')

    return clf

model=train_data(x_train,y_train)

def test_data(model,test_data):
    #Predicting RNA sequence is interacting or non interacting on test data.
    y_pred=model.predict(test_data)

    #Loading new test csv and creating dataframe result to store the sequences along with predicted values.
    test_new=pd.read_csv('test.csv')
    result=pd.DataFrame({"Sequence":test_new["Sequence"],"label":y_pred})
    # print(result)
    #Converting the result dataframe into csv.
    #result.to_csv('/content/drive/MyDrive/bdmh_assignment2/random_forest_acc.csv',index=False)
    result.to_csv(outFile,index=False)
    #prinitng number of one's and zero's in predicted result.
    print(Counter(y_pred))

    return y_pred

y_pred=test_data(model,test_df)
print("predicted values:")
print(y_pred)